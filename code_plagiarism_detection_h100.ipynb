{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89803b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and specs\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac826551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix numpy binary incompatibility first\n",
    "!pip uninstall -y numpy\n",
    "!pip install numpy==1.26.4 --force-reinstall\n",
    "\n",
    "# Install required packages with compatible versions for Colab\n",
    "!pip install -q transformers==4.46.0\n",
    "!pip install -q datasets==3.2.0\n",
    "!pip install -q accelerate==1.2.0\n",
    "!pip install -q sentencepiece==0.2.0\n",
    "!pip install -q scikit-learn==1.6.0\n",
    "!pip install -q tokenizers==0.21.0\n",
    "\n",
    "# For H100 optimizations\n",
    "!pip install -q torch-tb-profiler\n",
    "# Flash attention installation (may take a few minutes)\n",
    "!pip install -q flash-attn --no-build-isolation\n",
    "\n",
    "print(\"âœ“ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Mount Google Drive to save models\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/code_plagiarism_model'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Models will be saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart runtime after package installation to avoid conflicts\n",
    "# Click Runtime > Restart Runtime in Colab menu, then run from this cell onwards\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModel,\n",
    "    AutoConfig,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    set_seed\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce56742",
   "metadata": {},
   "source": [
    "## Configuration for H100 GPU Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-adaptive configuration for fast training (30 min target)\n",
    "class Config:\n",
    "    # Model configuration\n",
    "    model_name = \"microsoft/codebert-base\"  # Pre-trained on code\n",
    "    max_length = 256  # Reduced from 512 for faster processing\n",
    "    \n",
    "    # Adaptive GPU optimizations - Works on T4 (15GB), V100 (16GB), A100 (40/80GB)\n",
    "    batch_size = 32  # Conservative for 15GB GPU (T4/Colab)\n",
    "    gradient_accumulation_steps = 4  # Effective batch = 128\n",
    "    effective_batch_size = batch_size * gradient_accumulation_steps  # 128\n",
    "    \n",
    "    # Training configuration - FAST MODE\n",
    "    learning_rate = 3e-5  # Slightly higher for faster convergence\n",
    "    num_epochs = 2  # Reduced from 5 for speed\n",
    "    warmup_ratio = 0.05  # Reduced warmup\n",
    "    weight_decay = 0.01\n",
    "    max_grad_norm = 1.0\n",
    "    \n",
    "    # Mixed precision optimizations\n",
    "    fp16 = True   # Use FP16 for memory efficiency\n",
    "    bf16 = False  # bf16 is better for H100, but FP16 works on all GPUs\n",
    "    tf32 = True   # Enable TF32 if available\n",
    "    use_flash_attention = False  # Disabled for compatibility\n",
    "    gradient_checkpointing = False  # Disabled for speed\n",
    "    \n",
    "    # Data loading optimization\n",
    "    num_workers = 2  # Reduced to save memory\n",
    "    prefetch_factor = 2  # Reduced prefetching\n",
    "    pin_memory = True\n",
    "    \n",
    "    # Output\n",
    "    output_dir = OUTPUT_DIR\n",
    "    logging_steps = 50\n",
    "    eval_steps = 500\n",
    "    save_steps = 1000\n",
    "    save_total_limit = 3\n",
    "    \n",
    "    # Advanced\n",
    "    optim = \"adamw_torch_fused\"  # Fused optimizer when available\n",
    "    ddp_find_unused_parameters = False\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Enable TF32 if available (H100/A100)\n",
    "if config.tf32 and torch.cuda.is_available():\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Clear CUDA cache to free memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in vars(config).items():\n",
    "    if not key.startswith('_'):\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# GPU info\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"\\nðŸ’» GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"âš¡ Optimized for your GPU size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031a5e8",
   "metadata": {},
   "source": [
    "## Load Dataset from HuggingFace\n",
    "\n",
    "We'll use the BigCloneBench dataset which contains code clone pairs labeled as clones or non-clones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the code clone detection dataset\n",
    "print(\"Loading dataset from HuggingFace...\")\n",
    "\n",
    "try:\n",
    "    # Primary dataset: BigCloneBench\n",
    "    dataset = load_dataset(\n",
    "        \"code_x_glue_cc_clone_detection_big_clone_bench\",\n",
    "        \"default\"\n",
    "    )\n",
    "    print(f\"Loaded BigCloneBench dataset\")\n",
    "    print(f\"Train samples: {len(dataset['train'])}\")\n",
    "    print(f\"Validation samples: {len(dataset['validation'])}\")\n",
    "    print(f\"Test samples: {len(dataset['test'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading primary dataset: {e}\")\n",
    "    print(\"Falling back to alternative dataset...\")\n",
    "    # Alternative: POJ-104 Clone Detection\n",
    "    dataset = load_dataset(\n",
    "        \"code_x_glue_cc_clone_detection_poj104\",\n",
    "        \"default\"\n",
    "    )\n",
    "\n",
    "# Show example\n",
    "print(\"\\nDataset example:\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a92f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST TRAINING MODE: Use subset for 30-minute training\n",
    "USE_FULL_DATASET = False  # Set to True for full training (will take much longer)\n",
    "\n",
    "# Use 15% of data for fast training while maintaining statistical significance\n",
    "if not USE_FULL_DATASET:\n",
    "    print(\"âš¡ FAST TRAINING MODE: Using subset for 30-min training...\")\n",
    "    train_size = min(50000, len(dataset['train']))  # ~15-20% of typical dataset\n",
    "    val_size = min(5000, len(dataset['validation']))\n",
    "    test_size = min(5000, len(dataset['test']))\n",
    "    \n",
    "    dataset['train'] = dataset['train'].select(range(train_size))\n",
    "    dataset['validation'] = dataset['validation'].select(range(val_size))\n",
    "    dataset['test'] = dataset['test'].select(range(test_size))\n",
    "    print(f\"Reduced train samples: {len(dataset['train'])}\")\n",
    "    print(f\"Reduced validation samples: {len(dataset['validation'])}\")\n",
    "    print(f\"Reduced test samples: {len(dataset['test'])}\")\n",
    "    print(f\"ðŸ’¡ To use full dataset, set USE_FULL_DATASET = True (will take hours)\")\n",
    "\n",
    "# Analyze label distribution\n",
    "train_labels = [item['label'] for item in dataset['train']]\n",
    "print(f\"\\nLabel distribution in training set:\")\n",
    "print(f\"  Clones (1): {sum(train_labels)} ({sum(train_labels)/len(train_labels)*100:.2f}%)\")\n",
    "print(f\"  Non-clones (0): {len(train_labels)-sum(train_labels)} ({(1-sum(train_labels)/len(train_labels))*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e30a37",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b42100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "# Add special tokens if needed\n",
    "special_tokens = {\n",
    "    'additional_special_tokens': ['<CODE>', '</CODE>', '<FUNC>', '</FUNC>']\n",
    "}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "print(f\"Tokenizer loaded. Vocab size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory before model initialization\n",
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"ðŸ§¹ Cleared GPU cache\")\n",
    "    \n",
    "    # Show available memory\n",
    "    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    gpu_memory_reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    gpu_memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    print(f\"GPU Memory: {gpu_memory_allocated:.2f} GB allocated / {gpu_memory_total:.2f} GB total\")\n",
    "\n",
    "# Define the Siamese Network for Code Clone Detection\n",
    "class CodeCloneDetector(nn.Module):\n",
    "    \"\"\"Siamese network using CodeBERT for code clone detection\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, hidden_size=768, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pre-trained CodeBERT\n",
    "        model_config = AutoConfig.from_pretrained(model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(model_name, config=model_config)\n",
    "        \n",
    "        # Resize embeddings if we added special tokens\n",
    "        self.encoder.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        # Gradient checkpointing disabled for speed in fast training mode\n",
    "        # if config.gradient_checkpointing:\n",
    "        #     self.encoder.gradient_checkpointing_enable()\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 4, 512),  # Concatenate + element-wise ops\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 2)  # Binary classification\n",
    "        )\n",
    "        \n",
    "    def encode(self, input_ids, attention_mask):\n",
    "        \"\"\"Encode a code snippet\"\"\"\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        # Use [CLS] token representation\n",
    "        return outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2, labels=None):\n",
    "        \"\"\"Forward pass for two code snippets\"\"\"\n",
    "        # Encode both code snippets\n",
    "        emb1 = self.encode(input_ids1, attention_mask1)\n",
    "        emb2 = self.encode(input_ids2, attention_mask2)\n",
    "        \n",
    "        # Compute similarity features\n",
    "        diff = torch.abs(emb1 - emb2)  # Element-wise difference\n",
    "        prod = emb1 * emb2  # Element-wise product\n",
    "        \n",
    "        # Concatenate all features\n",
    "        features = torch.cat([emb1, emb2, diff, prod], dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits,\n",
    "            'embeddings': (emb1, emb2)\n",
    "        }\n",
    "\n",
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = CodeCloneDetector(config.model_name)\n",
    "model = model.cuda()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a824855",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeCloneDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for code clone detection\"\"\"\n",
    "    \n",
    "    def __init__(self, hf_dataset, tokenizer, max_length=512):\n",
    "        self.data = hf_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Get code snippets\n",
    "        code1 = item.get('func1', item.get('code1', ''))\n",
    "        code2 = item.get('func2', item.get('code2', ''))\n",
    "        label = item['label']\n",
    "        \n",
    "        # Tokenize code1\n",
    "        encoding1 = self.tokenizer(\n",
    "            code1,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize code2\n",
    "        encoding2 = self.tokenizer(\n",
    "            code2,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids1': encoding1['input_ids'].squeeze(),\n",
    "            'attention_mask1': encoding1['attention_mask'].squeeze(),\n",
    "            'input_ids2': encoding2['input_ids'].squeeze(),\n",
    "            'attention_mask2': encoding2['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = CodeCloneDataset(dataset['train'], tokenizer, config.max_length)\n",
    "val_dataset = CodeCloneDataset(dataset['validation'], tokenizer, config.max_length)\n",
    "test_dataset = CodeCloneDataset(dataset['test'], tokenizer, config.max_length)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Create dataloaders with H100 optimizations\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory,\n",
    "    prefetch_factor=config.prefetch_factor,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory,\n",
    "    prefetch_factor=config.prefetch_factor,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory\n",
    ")\n",
    "\n",
    "print(\"Dataloaders created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046bfbc",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Calculate total steps\n",
    "total_steps = len(train_loader) * config.num_epochs // config.gradient_accumulation_steps\n",
    "warmup_steps = int(total_steps * config.warmup_ratio)\n",
    "\n",
    "print(f\"Total training steps: {total_steps}\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")\n",
    "\n",
    "# Initialize optimizer with fused implementation for A100\n",
    "try:\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay,\n",
    "        fused=True  # Fused optimizer for speed\n",
    "    )\n",
    "    print(\"âœ“ Using fused AdamW optimizer\")\n",
    "except:\n",
    "    # Fallback if fused not available\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    print(\"âœ“ Using standard AdamW optimizer\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Mixed precision training with FP16 for A100 (faster than bf16)\n",
    "scaler = GradScaler(enabled=config.fp16)\n",
    "\n",
    "print(f\"\\nâš¡ Training optimizations:\")\n",
    "print(f\"  - Batch size: {config.batch_size}\")\n",
    "print(f\"  - Sequence length: {config.max_length}\")\n",
    "print(f\"  - Mixed precision: {'FP16' if config.fp16 else 'BF16' if config.bf16 else 'FP32'}\")\n",
    "print(f\"  - Gradient checkpointing: {config.gradient_checkpointing}\")\n",
    "print(f\"  - Expected time per epoch: ~15 minutes\")\n",
    "print(\"\\nOptimizer and scheduler initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"Evaluate model on validation/test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Move to device\n",
    "            input_ids1 = batch['input_ids1'].to(device)\n",
    "            attention_mask1 = batch['attention_mask1'].to(device)\n",
    "            input_ids2 = batch['input_ids2'].to(device)\n",
    "            attention_mask2 = batch['attention_mask2'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass with autocast for bf16\n",
    "            with autocast(dtype=torch.bfloat16 if config.bf16 else torch.float16, enabled=config.bf16 or config.fp16):\n",
    "                outputs = model(\n",
    "                    input_ids1, attention_mask1,\n",
    "                    input_ids2, attention_mask2,\n",
    "                    labels\n",
    "                )\n",
    "            \n",
    "            total_loss += outputs['loss'].item()\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # Probability of being a clone\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='binary'\n",
    "    )\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcce808",
   "metadata": {},
   "source": [
    "## Training Loop (H100 Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c16ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        # Move to device\n",
    "        input_ids1 = batch['input_ids1'].to(device, non_blocking=True)\n",
    "        attention_mask1 = batch['attention_mask1'].to(device, non_blocking=True)\n",
    "        input_ids2 = batch['input_ids2'].to(device, non_blocking=True)\n",
    "        attention_mask2 = batch['attention_mask2'].to(device, non_blocking=True)\n",
    "        labels = batch['labels'].to(device, non_blocking=True)\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with autocast(dtype=torch.bfloat16 if config.bf16 else torch.float16, enabled=config.bf16 or config.fp16):\n",
    "            outputs = model(\n",
    "                input_ids1, attention_mask1,\n",
    "                input_ids2, attention_mask2,\n",
    "                labels\n",
    "            )\n",
    "            loss = outputs['loss'] / config.gradient_accumulation_steps\n",
    "        \n",
    "        # Backward pass\n",
    "        if config.fp16 and scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        total_loss += loss.item() * config.gradient_accumulation_steps\n",
    "        \n",
    "        # Update weights every gradient_accumulation_steps\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            # Gradient clipping\n",
    "            if config.fp16 and scaler is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item() * config.gradient_accumulation_steps:.4f}\",\n",
    "            'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "print(\"Training function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "best_f1 = 0\n",
    "best_model_path = None\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': [],\n",
    "    'val_f1': [],\n",
    "    'val_auc': []\n",
    "}\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Epoch {epoch + 1}/{config.num_epochs}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, epoch)\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    val_metrics = evaluate(model, val_loader, device)\n",
    "    \n",
    "    print(f\"\\nValidation Metrics:\")\n",
    "    print(f\"  Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {val_metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall: {val_metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score: {val_metrics['f1']:.4f}\")\n",
    "    print(f\"  AUC-ROC: {val_metrics['auc']:.4f}\")\n",
    "    \n",
    "    # Save history\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['val_loss'].append(val_metrics['loss'])\n",
    "    training_history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "    training_history['val_f1'].append(val_metrics['f1'])\n",
    "    training_history['val_auc'].append(val_metrics['auc'])\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['f1'] > best_f1:\n",
    "        best_f1 = val_metrics['f1']\n",
    "        best_model_path = os.path.join(config.output_dir, f'best_model_epoch_{epoch+1}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_metrics': val_metrics,\n",
    "            'config': vars(config)\n",
    "        }, best_model_path)\n",
    "        print(f\"\\nâœ“ New best model saved! F1: {best_f1:.4f}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint_path = os.path.join(config.output_dir, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'training_history': training_history\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best F1 Score: {best_f1:.4f}\")\n",
    "print(f\"Best model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ae8ee",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(training_history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0, 0].plot(training_history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(training_history['val_accuracy'], label='Accuracy', marker='o', color='green')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Validation Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# F1 Score\n",
    "axes[1, 0].plot(training_history['val_f1'], label='F1 Score', marker='o', color='orange')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].set_title('Validation F1 Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# AUC\n",
    "axes[1, 1].plot(training_history['val_auc'], label='AUC-ROC', marker='o', color='red')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('AUC-ROC')\n",
    "axes[1, 1].set_title('Validation AUC-ROC')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config.output_dir, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4480e",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "print(\"Loading best model for final evaluation...\")\n",
    "checkpoint = torch.load(best_model_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_metrics = evaluate(model, test_loader, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final Test Set Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Loss: {test_metrics['loss']:.4f}\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"AUC-ROC: {test_metrics['auc']:.4f}\")\n",
    "\n",
    "# Save test results\n",
    "test_results = {\n",
    "    'test_metrics': test_metrics,\n",
    "    'training_history': training_history,\n",
    "    'config': vars(config),\n",
    "    'best_epoch': checkpoint['epoch']\n",
    "}\n",
    "\n",
    "with open(os.path.join(config.output_dir, 'test_results.json'), 'w') as f:\n",
    "    json.dump({k: v if not isinstance(v, np.floating) else float(v) \n",
    "               for k, v in test_results.items()}, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nTest results saved to {config.output_dir}/test_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffdb0e",
   "metadata": {},
   "source": [
    "## Save Model and Tokenizer for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a52f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model in deployment format\n",
    "final_model_dir = os.path.join(config.output_dir, 'final_model')\n",
    "os.makedirs(final_model_dir, exist_ok=True)\n",
    "\n",
    "print(\"Saving model for deployment...\")\n",
    "\n",
    "# Save model architecture and weights\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'model_name': config.model_name,\n",
    "        'hidden_size': 768,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'test_metrics': test_metrics\n",
    "}, os.path.join(final_model_dir, 'model.pt'))\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "# Save configuration\n",
    "config_dict = {\n",
    "    'model_name': config.model_name,\n",
    "    'max_length': config.max_length,\n",
    "    'version': '1.0.0',\n",
    "    'training_date': '2026-01-20',\n",
    "    'test_f1': float(test_metrics['f1']),\n",
    "    'test_accuracy': float(test_metrics['accuracy'])\n",
    "}\n",
    "\n",
    "with open(os.path.join(final_model_dir, 'config.json'), 'w') as f:\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Model saved to: {final_model_dir}\")\n",
    "print(\"\\nDeployment files:\")\n",
    "print(\"  - model.pt (model weights)\")\n",
    "print(\"  - config.json (model configuration)\")\n",
    "print(\"  - tokenizer files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a697f",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clone(code1, code2, model, tokenizer, device, max_length=512):\n",
    "    \"\"\"Predict if two code snippets are clones\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding1 = tokenizer(\n",
    "        code1,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    encoding2 = tokenizer(\n",
    "        code2,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            encoding1['input_ids'],\n",
    "            encoding1['attention_mask'],\n",
    "            encoding2['input_ids'],\n",
    "            encoding2['attention_mask']\n",
    "        )\n",
    "    \n",
    "    probs = F.softmax(outputs['logits'], dim=-1)\n",
    "    clone_prob = probs[0, 1].item()\n",
    "    prediction = 'Clone' if clone_prob > 0.5 else 'Not Clone'\n",
    "    \n",
    "    return {\n",
    "        'prediction': prediction,\n",
    "        'clone_probability': clone_prob,\n",
    "        'confidence': max(clone_prob, 1 - clone_prob)\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "code_snippet_1 = \"\"\"\n",
    "def calculate_sum(numbers):\n",
    "    total = 0\n",
    "    for num in numbers:\n",
    "        total += num\n",
    "    return total\n",
    "\"\"\"\n",
    "\n",
    "code_snippet_2 = \"\"\"\n",
    "def sum_numbers(arr):\n",
    "    result = 0\n",
    "    for x in arr:\n",
    "        result = result + x\n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "code_snippet_3 = \"\"\"\n",
    "def factorial(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return n * factorial(n - 1)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 1: Similar functions\")\n",
    "result = predict_clone(code_snippet_1, code_snippet_2, model, tokenizer, device)\n",
    "print(f\"Prediction: {result['prediction']}\")\n",
    "print(f\"Clone Probability: {result['clone_probability']:.4f}\")\n",
    "print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "\n",
    "print(\"\\nExample 2: Different functions\")\n",
    "result = predict_clone(code_snippet_1, code_snippet_3, model, tokenizer, device)\n",
    "print(f\"Prediction: {result['prediction']}\")\n",
    "print(f\"Clone Probability: {result['clone_probability']:.4f}\")\n",
    "print(f\"Confidence: {result['confidence']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8012b74",
   "metadata": {},
   "source": [
    "## Export to ONNX (Optional - for Production Deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to ONNX format for faster inference\n",
    "print(\"Exporting model to ONNX format...\")\n",
    "\n",
    "try:\n",
    "    # Create dummy inputs\n",
    "    dummy_input_ids = torch.randint(0, len(tokenizer), (1, config.max_length)).to(device)\n",
    "    dummy_attention_mask = torch.ones((1, config.max_length)).to(device)\n",
    "    \n",
    "    # Export\n",
    "    onnx_path = os.path.join(final_model_dir, 'model.onnx')\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (dummy_input_ids, dummy_attention_mask, dummy_input_ids, dummy_attention_mask),\n",
    "        onnx_path,\n",
    "        input_names=['input_ids1', 'attention_mask1', 'input_ids2', 'attention_mask2'],\n",
    "        output_names=['logits'],\n",
    "        dynamic_axes={\n",
    "            'input_ids1': {0: 'batch_size'},\n",
    "            'attention_mask1': {0: 'batch_size'},\n",
    "            'input_ids2': {0: 'batch_size'},\n",
    "            'attention_mask2': {0: 'batch_size'},\n",
    "            'logits': {0: 'batch_size'}\n",
    "        },\n",
    "        opset_version=14\n",
    "    )\n",
    "    print(f\"âœ“ ONNX model exported to: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"ONNX export failed: {e}\")\n",
    "    print(\"This is optional and doesn't affect the trained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae61a46",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ce57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: {config.model_name}\")\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(val_dataset):,}\")\n",
    "print(f\"Test samples: {len(test_dataset):,}\")\n",
    "print(f\"\\nTotal epochs: {config.num_epochs}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Effective batch size: {config.effective_batch_size}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"\\nBest validation F1: {best_f1:.4f}\")\n",
    "print(f\"\\nFinal Test Metrics:\")\n",
    "print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"  F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"  AUC-ROC: {test_metrics['auc']:.4f}\")\n",
    "print(f\"\\nModel saved to: {final_model_dir}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"1. Download the model files from Google Drive\")\n",
    "print(\"2. Integrate with your backend API\")\n",
    "print(\"3. Test on your own code samples\")\n",
    "print(\"4. Fine-tune further if needed on domain-specific data\")\n",
    "print(\"5. Deploy to production environment\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
